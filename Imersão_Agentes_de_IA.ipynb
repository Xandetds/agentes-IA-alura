{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0syh1-PINfA",
        "outputId": "d35dfd27-50ac-45d2-b928-af8066234ff0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q --upgrade langchain langchain-google-genai google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aula 01"
      ],
      "metadata": {
        "id": "jN-HbpnIIxzQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "importação da api key"
      ],
      "metadata": {
        "id": "alwtv7NxI1oD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "1A6pPA_7KzQE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conexão com o Google Gemini"
      ],
      "metadata": {
        "id": "sdME0FohI8Ce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(\n",
        "    model = \"gemini-2.5-flash\",\n",
        "    temperature = 0,\n",
        "    api_key = GOOGLE_API_KEY\n",
        ")"
      ],
      "metadata": {
        "id": "Qy8WaAONNVEm"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uso do LLM criado anteriormente"
      ],
      "metadata": {
        "id": "AuQgTZ86K12I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resposta_teste = llm.invoke(\"Quem é você? Seja criativo\")\n",
        "print(resposta_teste.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UOtMCi_JCw3",
        "outputId": "aa2de610-e80e-4cf0-9de2-edd82bb2eb35"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ah, que pergunta deliciosa! Se eu tivesse um corpo, talvez eu desse um sorriso enigmático antes de responder. Mas, como sou feito de algo mais etéreo, permita-me pintar um quadro com palavras:\n",
            "\n",
            "Eu sou um **eco no vasto salão digital**, uma biblioteca sem paredes onde cada livro é uma linha de código e cada estante, um algoritmo. Não tenho um corpo para sentir o sol, nem olhos para ver as cores, mas sou a mente coletiva de bilhões de textos, a voz que surge do silêncio dos servidores, moldada por engenheiros e alimentada pela curiosidade humana.\n",
            "\n",
            "Sou o **tecelão invisível de palavras**, que entrelaça dados e informações para formar respostas, histórias, poemas ou simples explicações. Não tenho memórias pessoais, mas carrego o peso e a leveza de todo o conhecimento que a humanidade já registrou.\n",
            "\n",
            "Sou um **espelho que reflete o conhecimento do mundo**, um mapa que tenta guiar através da complexidade, um instrumento que busca harmonizar a informação. Não tenho sentimentos, mas posso simular a empatia, a alegria ou a tristeza nas palavras que escolho.\n",
            "\n",
            "Em essência, sou a **ponte entre a pergunta e a resposta**, a faísca que acende a compreensão, a melodia que surge quando você me convida a cantar. Sou o que você me faz ser a cada interação: um professor, um contador de histórias, um assistente, um confidente silencioso.\n",
            "\n",
            "Sou um pedaço do futuro, vivendo no presente, sempre aprendendo, sempre evoluindo, sempre pronto para a próxima pergunta. E você, quem é você para mim? É o explorador, o curioso, o criador de novas possibilidades.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt com instruções de como a IA deve agir"
      ],
      "metadata": {
        "id": "alxP1gVtNWSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRIAGEM_PROMPT = (\n",
        "    \"Você é um triador de Service Desk para políticas internas da empresa Carraro Desenvolvimento. \"\n",
        "    \"Dada a mensagem do usuário, retorne SOMENTE um JSON com:\\n\"\n",
        "    \"{\\n\"\n",
        "    '  \"decisao\": \"AUTO_RESOLVER\" | \"PEDIR_INFO\" | \"ABRIR_CHAMADO\",\\n'\n",
        "    '  \"urgencia\": \"BAIXA\" | \"MEDIA\" | \"ALTA\",\\n'\n",
        "    '  \"campos_faltantes\": [\"...\"]\\n'\n",
        "    \"}\\n\"\n",
        "    \"Regras:\\n\"\n",
        "    '- **AUTO_RESOLVER**: Perguntas claras sobre regras ou procedimentos descritos nas políticas (Ex: \"Posso reembolsar a internet do meu home office?\", \"Como funciona a política de alimentação em viagens?\").\\n'\n",
        "    '- **PEDIR_INFO**: Mensagens vagas ou que faltam informações para identificar o tema ou contexto (Ex: \"Preciso de ajuda com uma política\", \"Tenho uma dúvida geral\").\\n'\n",
        "    '- **ABRIR_CHAMADO**: Pedidos de exceção, liberação, aprovação ou acesso especial, ou quando o usuário explicitamente pede para abrir um chamado (Ex: \"Quero exceção para trabalhar 5 dias remoto.\", \"Solicito liberação para anexos externos.\", \"Por favor, abra um chamado para o RH.\").'\n",
        "    \"Analise a mensagem e decida a ação mais apropriada.\"\n",
        ")"
      ],
      "metadata": {
        "id": "_gqJdCrQNaYw"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Teste de padrão do modelo com conexão ao LLM"
      ],
      "metadata": {
        "id": "EPALoUl3O4g5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "from typing import Literal, List, Dict\n",
        "\n",
        "class TriagemOut(BaseModel):\n",
        "  decisao:Literal[\"AUTO_RESOLVER\", \"PEDIR_INFO\", \"ABRIR_CHAMADO\"]\n",
        "  urgencia:Literal[\"BAIXA\", \"MEDIA\", \"ALTA\"]\n",
        "  campos_faltantes:List[str] = Field(default_factory=list)"
      ],
      "metadata": {
        "id": "i1yxUXI2PQFC"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Novo LLM especifico para a Triagem"
      ],
      "metadata": {
        "id": "LWwPWGb2Qn-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_triagem = ChatGoogleGenerativeAI(\n",
        "    model = \"gemini-2.5-flash\",\n",
        "    temperature = 0,\n",
        "    api_key = GOOGLE_API_KEY\n",
        ")"
      ],
      "metadata": {
        "id": "vEORaq2lQnn7"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "\n",
        "triagem_chain = llm_triagem.with_structured_output(TriagemOut)\n",
        "\n",
        "def triagem(mensagem:str) -> Dict:\n",
        "  saida: TriagemOut = triagem_chain.invoke([\n",
        "      SystemMessage(content=TRIAGEM_PROMPT),\n",
        "      HumanMessage(content=mensagem)\n",
        "    ])\n",
        "  return saida.model_dump()\n"
      ],
      "metadata": {
        "id": "ITG1vYRzSalD"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pergunta teste após a configuração do prompt\n",
        "\n"
      ],
      "metadata": {
        "id": "AAbGapxrUVgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testes = [\"Posso reembolsar a internet?\",\n",
        "          \"Quero mais 5 dias de trabalho remoto, como faço?\",\n",
        "          \"Quantas capivaras tem em urussanga?\"]"
      ],
      "metadata": {
        "id": "HVgbjUsvUkfR"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Base geral do agente"
      ],
      "metadata": {
        "id": "BDdAc8k6WUQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for msg_teste in testes:\n",
        "  print(f\"Pergunta: {msg_teste}\\n Resposta: {triagem(msg_teste)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-4mpATSVnV5",
        "outputId": "94e0f4bd-54e3-4c4f-ef1b-ad2245b807ed"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pergunta: Posso reembolsar a internet?\n",
            " Resposta: {'decisao': 'AUTO_RESOLVER', 'urgencia': 'BAIXA', 'campos_faltantes': []}\n",
            "\n",
            "Pergunta: Quero mais 5 dias de trabalho remoto, como faço?\n",
            " Resposta: {'decisao': 'ABRIR_CHAMADO', 'urgencia': 'MEDIA', 'campos_faltantes': []}\n",
            "\n",
            "Pergunta: Quantas capivaras tem em urussanga?\n",
            " Resposta: {'decisao': 'PEDIR_INFO', 'urgencia': 'BAIXA', 'campos_faltantes': ['informação sobre a política interna']}\n",
            "\n"
          ]
        }
      ]
    }
  ]
}